{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47ac10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import th∆∞ vi·ªán\n",
    "import json\n",
    "import concurrent.futures\n",
    "import re\n",
    "from textwrap import dedent\n",
    "from statistics import mean\n",
    "from dotenv import load_dotenv\n",
    "from anthropic import Anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b784b94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kh·ªüi t·∫°o Client v√† c√°c h√†m h·ªó tr·ª£\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = Anthropic()\n",
    "model = \"claude-3-5-haiku-latest\"\n",
    "\n",
    "\n",
    "def add_user_message(messages, text):\n",
    "    user_message = {\"role\": \"user\", \"content\": text}\n",
    "    messages.append(user_message)\n",
    "\n",
    "\n",
    "def add_assistant_message(messages, text):\n",
    "    assistant_message = {\"role\": \"assistant\", \"content\": text}\n",
    "    messages.append(assistant_message)\n",
    "\n",
    "\n",
    "def chat(messages, system=None, temperature=1.0, stop_sequences=[]):\n",
    "    params = {\n",
    "        \"model\": model,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "        \"stop_sequences\": stop_sequences,\n",
    "    }\n",
    "\n",
    "    if system:\n",
    "        params[\"system\"] = system\n",
    "\n",
    "    message = client.messages.create(**params)\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√¥ng c·ª• t·∫°o b√°o c√°o ti·∫øng Vi·ªát\n",
    "def generate_prompt_evaluation_report(evaluation_results):\n",
    "    total_tests = len(evaluation_results)\n",
    "    scores = [result[\"score\"] for result in evaluation_results]\n",
    "    avg_score = mean(scores) if scores else 0\n",
    "    max_possible_score = 10\n",
    "    pass_rate = (\n",
    "        100 * len([s for s in scores if s >= 7]) / total_tests\n",
    "        if total_tests\n",
    "        else 0\n",
    "    )\n",
    "\n",
    "    html = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"vi\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "        <title>B√°o C√°o ƒê√°nh Gi√° Prompt</title>\n",
    "        <style>\n",
    "            body {{\n",
    "                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "                line-height: 1.6;\n",
    "                margin: 0;\n",
    "                padding: 20px;\n",
    "                color: #333;\n",
    "            }}\n",
    "            .header {{\n",
    "                background-color: #f0f0f0;\n",
    "                padding: 20px;\n",
    "                border-radius: 5px;\n",
    "                margin-bottom: 20px;\n",
    "            }}\n",
    "            .summary-stats {{\n",
    "                display: flex;\n",
    "                justify-content: space-between;\n",
    "                flex-wrap: wrap;\n",
    "                gap: 10px;\n",
    "            }}\n",
    "            .stat-box {{\n",
    "                background-color: #fff;\n",
    "                border-radius: 5px;\n",
    "                padding: 15px;\n",
    "                box-shadow: 0 2px 5px rgba(0,0,0,0.1);\n",
    "                flex-basis: 30%;\n",
    "                min-width: 200px;\n",
    "            }}\n",
    "            .stat-value {{\n",
    "                font-size: 24px;\n",
    "                font-weight: bold;\n",
    "                margin-top: 5px;\n",
    "            }}\n",
    "            table {{\n",
    "                width: 100%;\n",
    "                border-collapse: collapse;\n",
    "                margin-top: 20px;\n",
    "            }}\n",
    "            th {{\n",
    "                background-color: #4a4a4a;\n",
    "                color: white;\n",
    "                text-align: left;\n",
    "                padding: 12px;\n",
    "            }}\n",
    "            td {{\n",
    "                padding: 10px;\n",
    "                border-bottom: 1px solid #ddd;\n",
    "                vertical-align: top;\n",
    "            }}\n",
    "            tr:nth-child(even) {{\n",
    "                background-color: #f9f9f9;\n",
    "            }}\n",
    "            .output-cell {{\n",
    "                white-space: pre-wrap;\n",
    "            }}\n",
    "            .score {{\n",
    "                font-weight: bold;\n",
    "                padding: 5px 10px;\n",
    "                border-radius: 3px;\n",
    "                display: inline-block;\n",
    "            }}\n",
    "            .score-high {{\n",
    "                background-color: #c8e6c9;\n",
    "                color: #2e7d32;\n",
    "            }}\n",
    "            .score-medium {{\n",
    "                background-color: #fff9c4;\n",
    "                color: #f57f17;\n",
    "            }}\n",
    "            .score-low {{\n",
    "                background-color: #ffcdd2;\n",
    "                color: #c62828;\n",
    "            }}\n",
    "            .output {{\n",
    "                overflow: auto;\n",
    "                white-space: pre-wrap;\n",
    "            }}\n",
    "            .output pre {{\n",
    "                background-color: #f5f5f5;\n",
    "                border: 1px solid #ddd;\n",
    "                border-radius: 4px;\n",
    "                padding: 10px;\n",
    "                margin: 0;\n",
    "                font-family: 'Consolas', 'Monaco', 'Courier New', monospace;\n",
    "                font-size: 14px;\n",
    "                line-height: 1.4;\n",
    "                color: #333;\n",
    "                box-shadow: inset 0 1px 3px rgba(0, 0, 0, 0.1);\n",
    "                overflow-x: auto;\n",
    "                white-space: pre-wrap;\n",
    "                word-wrap: break-word;\n",
    "            }}\n",
    "            td {{\n",
    "                width: 20%;\n",
    "            }}\n",
    "            .score-col {{\n",
    "                width: 80px;\n",
    "            }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div class=\"header\">\n",
    "            <h1>B√°o C√°o ƒê√°nh Gi√° Prompt</h1>\n",
    "            <div class=\"summary-stats\">\n",
    "                <div class=\"stat-box\">\n",
    "                    <div>T·ªïng S·ªë Test Case</div>\n",
    "                    <div class=\"stat-value\">{total_tests}</div>\n",
    "                </div>\n",
    "                <div class=\"stat-box\">\n",
    "                    <div>ƒêi·ªÉm Trung B√¨nh</div>\n",
    "                    <div class=\"stat-value\">{avg_score:.1f} / {max_possible_score}</div>\n",
    "                </div>\n",
    "                <div class=\"stat-box\">\n",
    "                    <div>T·ª∑ L·ªá ƒê·∫°t (‚â•7)</div>\n",
    "                    <div class=\"stat-value\">{pass_rate:.1f}%</div>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "        <table>\n",
    "            <thead>\n",
    "                <tr>\n",
    "                    <th>K·ªãch B·∫£n</th>\n",
    "                    <th>ƒê·∫ßu V√†o Prompt</th>\n",
    "                    <th>Ti√™u Ch√≠ Gi·∫£i Ph√°p</th>\n",
    "                    <th>K·∫øt Qu·∫£</th>\n",
    "                    <th>ƒêi·ªÉm</th>\n",
    "                    <th>L√Ω Lu·∫≠n</th>\n",
    "                </tr>\n",
    "            </thead>\n",
    "            <tbody>\n",
    "    \"\"\"\n",
    "\n",
    "    for result in evaluation_results:\n",
    "        prompt_inputs_html = \"<br>\".join(\n",
    "            [\n",
    "                f\"<strong>{key}:</strong> {value}\"\n",
    "                for key, value in result[\"test_case\"][\"prompt_inputs\"].items()\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        criteria_string = \"<br>‚Ä¢ \".join(\n",
    "            result[\"test_case\"][\"solution_criteria\"]\n",
    "        )\n",
    "\n",
    "        score = result[\"score\"]\n",
    "        if score >= 8:\n",
    "            score_class = \"score-high\"\n",
    "        elif score <= 5:\n",
    "            score_class = \"score-low\"\n",
    "        else:\n",
    "            score_class = \"score-medium\"\n",
    "\n",
    "        html += f\"\"\"\n",
    "            <tr>\n",
    "                <td>{result[\"test_case\"][\"scenario\"]}</td>\n",
    "                <td class=\"prompt-inputs\">{prompt_inputs_html}</td>\n",
    "                <td class=\"criteria\">‚Ä¢ {criteria_string}</td>\n",
    "                <td class=\"output\"><pre>{result[\"output\"]}</pre></td>\n",
    "                <td class=\"score-col\"><span class=\"score {score_class}\">{score}</span></td>\n",
    "                <td class=\"reasoning\">{result[\"reasoning\"]}</td>\n",
    "            </tr>\n",
    "        \"\"\"\n",
    "\n",
    "    html += \"\"\"\n",
    "            </tbody>\n",
    "        </table>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tri·ªÉn khai PromptEvaluator v·ªõi prompt ti·∫øng Vi·ªát\n",
    "class PromptEvaluator:\n",
    "    def __init__(self, max_concurrent_tasks=3):\n",
    "        self.max_concurrent_tasks = max_concurrent_tasks\n",
    "\n",
    "    def render(self, template_string, variables):\n",
    "        placeholders = re.findall(r\"{([^{}]+)}\", template_string)\n",
    "        result = template_string\n",
    "        for placeholder in placeholders:\n",
    "            if placeholder in variables:\n",
    "                result = result.replace(\n",
    "                    \"{\" + placeholder + \"}\", str(variables[placeholder])\n",
    "                )\n",
    "        return result.replace(\"{{\", \"{\").replace(\"}}\", \"}\")\n",
    "\n",
    "    def generate_unique_ideas(self, task_description, prompt_inputs_spec, num_cases):\n",
    "        \"\"\"T·∫°o danh s√°ch √Ω t∆∞·ªüng ƒë·ªôc ƒë√°o cho test case d·ª±a tr√™n m√¥ t·∫£ t√°c v·ª•\"\"\"\n",
    "        prompt = \"\"\"\n",
    "        T·∫°o {num_cases} √Ω t∆∞·ªüng ƒë·ªôc ƒë√°o v√† ƒëa d·∫°ng ƒë·ªÉ test m·ªôt prompt th·ª±c hi·ªán t√°c v·ª• sau:\n",
    "        \n",
    "        <m√¥_t·∫£_t√°c_v·ª•>\n",
    "        {task_description}\n",
    "        </m√¥_t·∫£_t√°c_v·ª•>\n",
    "\n",
    "        Prompt s·∫Ω nh·∫≠n c√°c ƒë·∫ßu v√†o sau:\n",
    "        <ƒë·∫ßu_v√†o_prompt>\n",
    "        {prompt_inputs_spec}\n",
    "        </ƒë·∫ßu_v√†o_prompt>\n",
    "        \n",
    "        M·ªói √Ω t∆∞·ªüng n√™n ƒë·∫°i di·ªán cho m·ªôt k·ªãch b·∫£n ho·∫∑c v√≠ d·ª• ri√™ng bi·ªát ƒë·ªÉ test c√°c kh√≠a c·∫°nh kh√°c nhau c·ªßa t√°c v·ª•.\n",
    "        \n",
    "        ƒê·ªãnh d·∫°ng ƒë·∫ßu ra:\n",
    "        Cung c·∫•p ph·∫£n h·ªìi d∆∞·ªõi d·∫°ng m·∫£ng JSON c√≥ c·∫•u tr√∫c, trong ƒë√≥ m·ªói item l√† m√¥ t·∫£ ng·∫Øn g·ªçn v·ªÅ √Ω t∆∞·ªüng.\n",
    "        \n",
    "        ƒê·∫£m b·∫£o m·ªói √Ω t∆∞·ªüng:\n",
    "        - R√µ r√†ng kh√°c bi·ªát v·ªõi c√°c √Ω t∆∞·ªüng kh√°c\n",
    "        - Li√™n quan ƒë·∫øn m√¥ t·∫£ t√°c v·ª•\n",
    "        - ƒê·ªß c·ª• th·ªÉ ƒë·ªÉ h∆∞·ªõng d·∫´n t·∫°o test case ƒë·∫ßy ƒë·ªß\n",
    "        - Nhanh ch√≥ng gi·∫£i quy·∫øt m√† kh√¥ng c·∫ßn t√≠nh to√°n ph·ª©c t·∫°p ho·∫∑c x·ª≠ l√Ω nhi·ªÅu b∆∞·ªõc\n",
    "        - C√≥ th·ªÉ gi·∫£i quy·∫øt v·ªõi kh√¥ng qu√° 400 token ƒë·∫ßu ra\n",
    "\n",
    "        Nh·ªõ r·∫±ng, ch·ªâ t·∫°o {num_cases} √Ω t∆∞·ªüng ƒë·ªôc ƒë√°o\n",
    "        \"\"\"\n",
    "\n",
    "        system_prompt = \"B·∫°n l√† m·ªôt nh√† thi·∫øt k·∫ø k·ªãch b·∫£n test chuy√™n t·∫°o c√°c k·ªãch b·∫£n test ƒëa d·∫°ng v√† ƒë·ªôc ƒë√°o.\"\n",
    "\n",
    "        example_prompt_inputs = \"\"\n",
    "        for key, value in prompt_inputs_spec.items():\n",
    "            val = value.replace(\"\\n\", \"\\\\n\")\n",
    "            example_prompt_inputs += f'\"{key}\": str # {val},'\n",
    "\n",
    "        rendered_prompt = self.render(\n",
    "            dedent(prompt),\n",
    "            {\n",
    "                \"task_description\": task_description,\n",
    "                \"num_cases\": num_cases,\n",
    "                \"prompt_inputs_spec\": example_prompt_inputs,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        messages = []\n",
    "        add_user_message(messages, rendered_prompt)\n",
    "        add_assistant_message(messages, \"```json\")\n",
    "        text = chat(\n",
    "            messages,\n",
    "            stop_sequences=[\"```\"],\n",
    "            system=system_prompt,\n",
    "            temperature=1.0,\n",
    "        )\n",
    "\n",
    "        return json.loads(text)\n",
    "\n",
    "    def generate_test_case(self, task_description, idea, prompt_inputs_spec={}):\n",
    "        \"\"\"T·∫°o m·ªôt test case d·ª±a tr√™n m√¥ t·∫£ t√°c v·ª• v√† √Ω t∆∞·ªüng c·ª• th·ªÉ\"\"\"\n",
    "\n",
    "        example_prompt_inputs = \"\"\n",
    "        for key, value in prompt_inputs_spec.items():\n",
    "            val = value.replace(\"\\n\", \"\\\\n\")\n",
    "            example_prompt_inputs += f'\"{key}\": \"GI√Å_TR·ªä_V√ç_D·ª§\", // {val}\\n'\n",
    "\n",
    "        allowed_keys = \", \".join(\n",
    "            [f'\"{key}\"' for key in prompt_inputs_spec.keys()]\n",
    "        )\n",
    "\n",
    "        prompt = \"\"\"\n",
    "        T·∫°o m·ªôt test case chi ti·∫øt cho ƒë√°nh gi√° prompt d·ª±a tr√™n:\n",
    "        \n",
    "        <m√¥_t·∫£_t√°c_v·ª•>\n",
    "        {task_description}\n",
    "        </m√¥_t·∫£_t√°c_v·ª•>\n",
    "        \n",
    "        <√Ω_t∆∞·ªüng_c·ª•_th·ªÉ>\n",
    "        {idea}\n",
    "        </√Ω_t∆∞·ªüng_c·ª•_th·ªÉ>\n",
    "        \n",
    "        <kh√≥a_ƒë·∫ßu_v√†o_ƒë∆∞·ª£c_ph√©p>\n",
    "        {allowed_keys}\n",
    "        </kh√≥a_ƒë·∫ßu_v√†o_ƒë∆∞·ª£c_ph√©p>\n",
    "        \n",
    "        ƒê·ªãnh d·∫°ng ƒë·∫ßu ra:\n",
    "        ```json\n",
    "        {{\n",
    "            \"prompt_inputs\": {{\n",
    "            {example_prompt_inputs}\n",
    "            }},\n",
    "            \"solution_criteria\": [\"ti√™u ch√≠ 1\", \"ti√™u ch√≠ 2\", ...]\n",
    "        }}\n",
    "        ```\n",
    "        \n",
    "        Y√äU C·∫¶U QUAN TR·ªåNG:\n",
    "        - B·∫°n CH·ªà ƒê∆Ø·ª¢C s·ª≠ d·ª•ng c√°c kh√≥a ƒë·∫ßu v√†o ch√≠nh x√°c sau trong prompt_inputs: {allowed_keys}        \n",
    "        - KH√îNG th√™m b·∫•t k·ª≥ kh√≥a b·ªï sung n√†o v√†o prompt_inputs\n",
    "        - T·∫•t c·∫£ kh√≥a ƒë∆∞·ª£c li·ªát k√™ trong kh√≥a_ƒë·∫ßu_v√†o_ƒë∆∞·ª£c_ph√©p ph·∫£i ƒë∆∞·ª£c bao g·ªìm trong ph·∫£n h·ªìi\n",
    "        - L√†m cho test case th·ª±c t·∫ø v√† h·ªØu √≠ch v·ªÅ m·∫∑t th·ª±c ti·ªÖn\n",
    "        - Bao g·ªìm c√°c ti√™u ch√≠ gi·∫£i ph√°p c√≥ th·ªÉ ƒëo l∆∞·ªùng v√† s√∫c t√≠ch\n",
    "        - Test case n√™n ƒë∆∞·ª£c ƒëi·ªÅu ch·ªânh theo √Ω t∆∞·ªüng c·ª• th·ªÉ ƒë∆∞·ª£c cung c·∫•p\n",
    "        - Nhanh ch√≥ng gi·∫£i quy·∫øt m√† kh√¥ng c·∫ßn t√≠nh to√°n ph·ª©c t·∫°p ho·∫∑c x·ª≠ l√Ω nhi·ªÅu b∆∞·ªõc\n",
    "        - C√≥ th·ªÉ gi·∫£i quy·∫øt v·ªõi kh√¥ng qu√° 400 token ƒë·∫ßu ra\n",
    "        \"\"\"\n",
    "\n",
    "        system_prompt = \"B·∫°n l√† m·ªôt ng∆∞·ªùi t·∫°o test case chuy√™n thi·∫øt k·∫ø c√°c k·ªãch b·∫£n ƒë√°nh gi√°.\"\n",
    "\n",
    "        rendered_prompt = self.render(\n",
    "            dedent(prompt),\n",
    "            {\n",
    "                \"allowed_keys\": allowed_keys,\n",
    "                \"task_description\": task_description,\n",
    "                \"idea\": idea,\n",
    "                \"example_prompt_inputs\": example_prompt_inputs,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        messages = []\n",
    "        add_user_message(messages, rendered_prompt)\n",
    "        add_assistant_message(messages, \"```json\")\n",
    "        text = chat(\n",
    "            messages,\n",
    "            stop_sequences=[\"```\"],\n",
    "            system=system_prompt,\n",
    "            temperature=0.7,\n",
    "        )\n",
    "\n",
    "        test_case = json.loads(text)\n",
    "        test_case[\"task_description\"] = task_description\n",
    "        test_case[\"scenario\"] = idea\n",
    "\n",
    "        return test_case\n",
    "\n",
    "    def generate_dataset(self, task_description, prompt_inputs_spec={}, num_cases=1, output_file=\"dataset.json\"):\n",
    "        \"\"\"T·∫°o test dataset d·ª±a tr√™n m√¥ t·∫£ t√°c v·ª• v√† l∆∞u v√†o file\"\"\"\n",
    "        ideas = self.generate_unique_ideas(\n",
    "            task_description, prompt_inputs_spec, num_cases\n",
    "        )\n",
    "\n",
    "        dataset = []\n",
    "        completed = 0\n",
    "        total = len(ideas)\n",
    "        last_reported_percentage = 0\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor(\n",
    "            max_workers=self.max_concurrent_tasks\n",
    "        ) as executor:\n",
    "            future_to_idea = {\n",
    "                executor.submit(\n",
    "                    self.generate_test_case,\n",
    "                    task_description,\n",
    "                    idea,\n",
    "                    prompt_inputs_spec,\n",
    "                ): idea\n",
    "                for idea in ideas\n",
    "            }\n",
    "\n",
    "            for future in concurrent.futures.as_completed(future_to_idea):\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    completed += 1\n",
    "                    current_percentage = int((completed / total) * 100)\n",
    "                    milestone_percentage = (current_percentage // 20) * 20\n",
    "\n",
    "                    if milestone_percentage > last_reported_percentage:\n",
    "                        print(f\"ƒê√£ t·∫°o {completed}/{total} test case\")\n",
    "                        last_reported_percentage = milestone_percentage\n",
    "\n",
    "                    dataset.append(result)\n",
    "                except Exception as e:\n",
    "                    print(f\"L·ªói khi t·∫°o test case: {e}\")\n",
    "\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(dataset, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    def grade_output(self, test_case, output, extra_criteria):\n",
    "        \"\"\"Ch·∫•m ƒëi·ªÉm ƒë·∫ßu ra c·ªßa test case s·ª≠ d·ª•ng model\"\"\"\n",
    "\n",
    "        prompt_inputs = \"\"\n",
    "        for key, value in test_case[\"prompt_inputs\"].items():\n",
    "            val = value.replace(\"\\n\", \"\\\\n\")\n",
    "            prompt_inputs += f'\"{key}\":\"{val}\",\\n'\n",
    "\n",
    "        extra_criteria_section = \"\"\n",
    "        if extra_criteria:\n",
    "            extra_criteria_template = \"\"\"\n",
    "            Y√™u c·∫ßu b·∫Øt bu·ªôc - B·∫§T K·ª≤ VI PH·∫†M N√ÄO C≈®NG D·∫™N ƒê·∫æN TH·∫§T B·∫†I T·ª∞ ƒê·ªòNG (ƒëi·ªÉm 3 ho·∫∑c th·∫•p h∆°n):\n",
    "            <ti√™u_ch√≠_quan_tr·ªçng_b·ªï_sung>\n",
    "            {extra_criteria}\n",
    "            </ti√™u_ch√≠_quan_tr·ªçng_b·ªï_sung>\n",
    "            \"\"\"\n",
    "            extra_criteria_section = self.render(\n",
    "                dedent(extra_criteria_template),\n",
    "                {\"extra_criteria\": extra_criteria},\n",
    "            )\n",
    "\n",
    "        eval_template = \"\"\"\n",
    "        Nhi·ªám v·ª• c·ªßa b·∫°n l√† ƒë√°nh gi√° gi·∫£i ph√°p do AI t·∫°o ra sau ƒë√¢y v·ªõi ƒê·ªò NGHI√äM NG·∫∂T C·ª∞C CAO.\n",
    "\n",
    "        M√¥ t·∫£ t√°c v·ª• g·ªëc:\n",
    "        <m√¥_t·∫£_t√°c_v·ª•>\n",
    "        {task_description}\n",
    "        </m√¥_t·∫£_t√°c_v·ª•>\n",
    "\n",
    "        ƒê·∫ßu v√†o t√°c v·ª• g·ªëc:\n",
    "        <ƒë·∫ßu_v√†o_t√°c_v·ª•>\n",
    "        {{ {prompt_inputs} }}\n",
    "        </ƒë·∫ßu_v√†o_t√°c_v·ª•>\n",
    "\n",
    "        Gi·∫£i ph√°p c·∫ßn ƒë√°nh gi√°:\n",
    "        <gi·∫£i_ph√°p>\n",
    "        {output}\n",
    "        </gi·∫£i_ph√°p>\n",
    "\n",
    "        Ti√™u ch√≠ b·∫°n n√™n s·ª≠ d·ª•ng ƒë·ªÉ ƒë√°nh gi√° gi·∫£i ph√°p:\n",
    "        <ti√™u_ch√≠>\n",
    "        {solution_criteria}\n",
    "        </ti√™u_ch√≠>\n",
    "\n",
    "        {extra_criteria_section}\n",
    "\n",
    "        H∆∞·ªõng d·∫´n ch·∫•m ƒëi·ªÉm:\n",
    "        * ƒêi·ªÉm 1-3: Gi·∫£i ph√°p kh√¥ng ƒë√°p ·ª©ng m·ªôt ho·∫∑c nhi·ªÅu y√™u c·∫ßu B·∫ÆT BU·ªòC\n",
    "        * ƒêi·ªÉm 4-6: Gi·∫£i ph√°p ƒë√°p ·ª©ng t·∫•t c·∫£ y√™u c·∫ßu b·∫Øt bu·ªôc nh∆∞ng c√≥ thi·∫øu s√≥t ƒë√°ng k·ªÉ trong ti√™u ch√≠ ph·ª•\n",
    "        * ƒêi·ªÉm 7-8: Gi·∫£i ph√°p ƒë√°p ·ª©ng t·∫•t c·∫£ y√™u c·∫ßu b·∫Øt bu·ªôc v√† h·∫ßu h·∫øt ti√™u ch√≠ ph·ª•, v·ªõi c√°c v·∫•n ƒë·ªÅ nh·ªè\n",
    "        * ƒêi·ªÉm 9-10: Gi·∫£i ph√°p ƒë√°p ·ª©ng t·∫•t c·∫£ ti√™u ch√≠ b·∫Øt bu·ªôc v√† ph·ª•\n",
    "\n",
    "        ƒê·ªãnh d·∫°ng ƒë·∫ßu ra\n",
    "        Cung c·∫•p ƒë√°nh gi√° c·ªßa b·∫°n d∆∞·ªõi d·∫°ng ƒë·ªëi t∆∞·ª£ng JSON c√≥ c·∫•u tr√∫c v·ªõi c√°c tr∆∞·ªùng sau:\n",
    "        - \"strengths\": M·∫£ng 1-3 ƒëi·ªÉm m·∫°nh ch√≠nh\n",
    "        - \"weaknesses\": M·∫£ng 1-3 lƒ©nh v·ª±c ch√≠nh c·∫ßn c·∫£i thi·ªán\n",
    "        - \"reasoning\": Gi·∫£i th√≠ch s√∫c t√≠ch v·ªÅ ƒë√°nh gi√° t·ªïng th·ªÉ c·ªßa b·∫°n\n",
    "        - \"score\": S·ªë t·ª´ 1-10\n",
    "\n",
    "        Ph·∫£n h·ªìi b·∫±ng JSON. Gi·ªØ ph·∫£n h·ªìi s√∫c t√≠ch v√† tr·ª±c ti·∫øp.\n",
    "        \"\"\"\n",
    "\n",
    "        eval_prompt = self.render(\n",
    "            dedent(eval_template),\n",
    "            {\n",
    "                \"task_description\": test_case[\"task_description\"],\n",
    "                \"prompt_inputs\": prompt_inputs,\n",
    "                \"output\": output,\n",
    "                \"solution_criteria\": \"\\n\".join(test_case[\"solution_criteria\"]),\n",
    "                \"extra_criteria_section\": extra_criteria_section,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        messages = []\n",
    "        add_user_message(messages, eval_prompt)\n",
    "        add_assistant_message(messages, \"```json\")\n",
    "        eval_text = chat(\n",
    "            messages,\n",
    "            stop_sequences=[\"```\"],\n",
    "            temperature=0.0,\n",
    "        )\n",
    "        return json.loads(eval_text)\n",
    "\n",
    "    def run_test_case(self, test_case, run_prompt_function, extra_criteria=None):\n",
    "        \"\"\"Ch·∫°y test case v√† ch·∫•m ƒëi·ªÉm k·∫øt qu·∫£\"\"\"\n",
    "        output = run_prompt_function(test_case[\"prompt_inputs\"])\n",
    "\n",
    "        model_grade = self.grade_output(test_case, output, extra_criteria)\n",
    "        model_score = model_grade[\"score\"]\n",
    "        reasoning = model_grade[\"reasoning\"]\n",
    "\n",
    "        return {\n",
    "            \"output\": output,\n",
    "            \"test_case\": test_case,\n",
    "            \"score\": model_score,\n",
    "            \"reasoning\": reasoning,\n",
    "        }\n",
    "\n",
    "    def run_evaluation(self, run_prompt_function, dataset_file, extra_criteria=None, json_output_file=\"output.json\", html_output_file=\"output.html\"):\n",
    "        \"\"\"Ch·∫°y ƒë√°nh gi√° tr√™n t·∫•t c·∫£ test case trong dataset\"\"\"\n",
    "        with open(dataset_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            dataset = json.load(f)\n",
    "\n",
    "        results = []\n",
    "        completed = 0\n",
    "        total = len(dataset)\n",
    "        last_reported_percentage = 0\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor(\n",
    "            max_workers=self.max_concurrent_tasks\n",
    "        ) as executor:\n",
    "            future_to_test_case = {\n",
    "                executor.submit(\n",
    "                    self.run_test_case,\n",
    "                    test_case,\n",
    "                    run_prompt_function,\n",
    "                    extra_criteria,\n",
    "                ): test_case\n",
    "                for test_case in dataset\n",
    "            }\n",
    "\n",
    "            for future in concurrent.futures.as_completed(future_to_test_case):\n",
    "                result = future.result()\n",
    "                completed += 1\n",
    "                current_percentage = int((completed / total) * 100)\n",
    "                milestone_percentage = (current_percentage // 20) * 20\n",
    "\n",
    "                if milestone_percentage > last_reported_percentage:\n",
    "                    print(f\"ƒê√£ ch·∫•m ƒëi·ªÉm {completed}/{total} test case\")\n",
    "                    last_reported_percentage = milestone_percentage\n",
    "                results.append(result)\n",
    "\n",
    "        average_score = mean([result[\"score\"] for result in results])\n",
    "        print(f\"ƒêi·ªÉm trung b√¨nh: {average_score}\")\n",
    "\n",
    "        with open(json_output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        html = generate_prompt_evaluation_report(results)\n",
    "        with open(html_output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(html)\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ghi789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o m·ªôt instance c·ªßa PromptEvaluator\n",
    "# TƒÉng max_concurrent_tasks ƒë·ªÉ c√≥ t√≠nh ƒë·ªìng th·ªùi cao h∆°n, nh∆∞ng c·∫©n th·∫≠n v·ªõi l·ªói rate limit!\n",
    "evaluator = PromptEvaluator(max_concurrent_tasks=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jkl012",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = evaluator.generate_dataset(\n",
    "    # M√¥ t·∫£ m·ª•c ƒë√≠ch ho·∫∑c m·ª•c ti√™u c·ªßa prompt b·∫°n ƒëang c·ªë g·∫Øng test\n",
    "    task_description=\"Vi·∫øt k·∫ø ho·∫°ch b·ªØa ƒÉn 1 ng√†y g·ªçn g√†ng, s√∫c t√≠ch cho m·ªôt v·∫≠n ƒë·ªông vi√™n\",\n",
    "    # M√¥ t·∫£ c√°c ƒë·∫ßu v√†o kh√°c nhau m√† prompt c·ªßa b·∫°n y√™u c·∫ßu\n",
    "    prompt_inputs_spec={\n",
    "        \"height\": \"Chi·ªÅu cao c·ªßa v·∫≠n ƒë·ªông vi√™n t√≠nh b·∫±ng cm\",\n",
    "        \"weight\": \"C√¢n n·∫∑ng c·ªßa v·∫≠n ƒë·ªông vi√™n t√≠nh b·∫±ng kg\",\n",
    "        \"goal\": \"M·ª•c ti√™u c·ªßa v·∫≠n ƒë·ªông vi√™n\",\n",
    "        \"restriction\": \"H·∫°n ch·∫ø ch·∫ø ƒë·ªô ƒÉn c·ªßa v·∫≠n ƒë·ªông vi√™n\"\n",
    "    },\n",
    "    # N∆°i ghi dataset ƒë∆∞·ª£c t·∫°o\n",
    "    output_file=\"dataset.vn.json\",\n",
    "    # S·ªë l∆∞·ª£ng test case c·∫ßn t·∫°o (khuy·∫øn ngh·ªã gi·ªØ s·ªë n√†y th·∫•p n·∫øu b·∫°n g·∫∑p l·ªói rate limit)\n",
    "    num_cases=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mno345",
   "metadata": {},
   "outputs": [],
   "source": "# ƒê·ªãnh nghƒ©a v√† ch·∫°y prompt b·∫°n mu·ªën ƒë√°nh gi√°, tr·∫£ v·ªÅ ƒë·∫ßu ra model th√¥\n# H√†m n√†y ƒë∆∞·ª£c th·ª±c thi m·ªôt l·∫ßn cho m·ªói test case\ndef run_prompt(prompt_inputs):\n    prompt = f\"\"\"\n    T·∫°o k·∫ø ho·∫°ch b·ªØa ƒÉn m·ªôt ng√†y cho v·∫≠n ƒë·ªông vi√™n ƒë√°p ·ª©ng c√°c h·∫°n ch·∫ø ch·∫ø ƒë·ªô ƒÉn c·ªßa h·ªç.\n\n    <th√¥ng_tin_v·∫≠n_ƒë·ªông_vi√™n>\n    - Chi·ªÅu cao: {prompt_inputs[\"height\"]}\n    - C√¢n n·∫∑ng: {prompt_inputs[\"weight\"]}\n    - M·ª•c ti√™u: {prompt_inputs[\"goal\"]}\n    - H·∫°n ch·∫ø ch·∫ø ƒë·ªô ƒÉn: {prompt_inputs[\"restriction\"]}\n    </th√¥ng_tin_v·∫≠n_ƒë·ªông_vi√™n>\n\n    H∆∞·ªõng d·∫´n:\n    1. Bao g·ªìm l∆∞·ª£ng calo h√†ng ng√†y ch√≠nh x√°c\n    2. Hi·ªÉn th·ªã l∆∞·ª£ng protein, ch·∫•t b√©o v√† carb\n    3. Ch·ªâ ƒë·ªãnh th·ªùi gian ƒÉn m·ªói b·ªØa\n    4. Ch·ªâ s·ª≠ d·ª•ng th·ª±c ph·∫©m ph√π h·ª£p v·ªõi h·∫°n ch·∫ø\n    5. Li·ªát k√™ t·∫•t c·∫£ kh·∫©u ph·∫ßn b·∫±ng gram\n    6. Gi·ªØ th√¢n thi·ªán v·ªõi ng√¢n s√°ch n·∫øu ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p\n\n    ƒê√¢y l√† v√≠ d·ª• v·ªõi ƒë·∫ßu v√†o m·∫´u v√† √Ω t∆∞·ªüng v·ªÅ ƒë·∫ßu ra l√Ω t∆∞·ªüng:\n    <ƒë·∫ßu_v√†o_m·∫´u>\n    chi·ªÅu cao: 180\n    c√¢n n·∫∑ng: 85\n    m·ª•c ti√™u: Hi·ªáu su·∫•t ƒë·ªânh cao trong thi ƒë·∫•u CrossFit\n    h·∫°n ch·∫ø: Kh√¥ng gluten\n    </ƒë·∫ßu_v√†o_m·∫´u>\n\n    <ƒë·∫ßu_ra_l√Ω_t∆∞·ªüng>\n    K·∫ø Ho·∫°ch B·ªØa ƒÇn Cho V·∫≠n ƒê·ªông Vi√™n CrossFit\n\n    T√≠nh To√°n Calo H√†ng Ng√†y:\n    - T·ª∑ L·ªá Trao ƒê·ªïi Ch·∫•t C∆° B·∫£n (BMR): 1,900 calo\n    - H·ªá S·ªë Ho·∫°t ƒê·ªông: 1.8 (T·∫≠p Luy·ªán C∆∞·ªùng ƒê·ªô Cao)\n    - T·ªïng Calo H√†ng Ng√†y: 3,420 calo\n\n    Ph√¢n Chia Ch·∫•t Dinh D∆∞·ª°ng ƒêa L∆∞·ª£ng:\n    - Protein: 30% (257g)\n    - Carbohydrate: 40% (342g)\n    - Ch·∫•t b√©o: 30% (114g)\n\n    K·∫ø Ho·∫°ch B·ªØa ƒÇn:\n\n    üç≥ B·ªØa S√°ng (7:00 AM) - 700 calo\n    - Ch√°o quinoa (150g)\n    - 4 l√≤ng tr·∫Øng tr·ª©ng + 2 tr·ª©ng nguy√™n qu·∫£ (200g)\n    - Hoa qu·∫£ t·ªïng h·ª£p (100g)\n    - B∆° h·∫°nh nh√¢n (30g)\n    - H·∫°t chia (15g)\n\n    ü•ó B·ªØa Ph·ª• Gi·ªØa S√°ng (10:00 AM) - 400 calo\n    - S·ªØa chua Hy L·∫°p (kh√¥ng b√©o, kh√¥ng gluten) (200g)\n    - H·∫°nh nh√¢n (30g)\n    - Chu·ªëi (100g)\n\n    üçΩÔ∏è B·ªØa Tr∆∞a (1:00 PM) - 800 calo\n    - ·ª®c g√† n∆∞·ªõng (200g)\n    - Khoai lang (150g)\n    - Rau c·ªß n∆∞·ªõng t·ªïng h·ª£p (200g)\n    - S·ªët d·∫ßu √¥ liu (30g)\n\n    ü•§ B·ªØa Ph·ª• Tr∆∞·ªõc T·∫≠p (4:00 PM) - 350 calo\n    - Protein shake g·∫°o (50g)\n    - Y·∫øn m·∫°ch kh√¥ng gluten (50g)\n    - Vi·ªát qu·∫•t (100g)\n\n    üèãÔ∏è B·ªØa Sau T·∫≠p (6:00 PM) - 750 calo\n    - C√° h·ªìi t·ª± nhi√™n (180g)\n    - Quinoa (100g)\n    - B√¥ng c·∫£i xanh h·∫•p (150g)\n    - B∆° (50g)\n\n    üåô B·ªØa Ph·ª• T·ªëi (9:00 PM) - 420 calo\n    - ·ª®c g√† t√¢y (100g)\n    - Ph√¥ mai cottage (√≠t b√©o, 150g)\n    - H·∫°nh nh√¢n (25g)\n\n    Hydration:\n    - U·ªëng n∆∞·ªõc: 4-5 l√≠t m·ªói ng√†y\n    - Khuy√™n d√πng th√™m ch·∫•t ƒëi·ªán gi·∫£i\n\n    M·∫πo Ti·∫øt Ki·ªám:\n    - Mua protein s·ªë l∆∞·ª£ng l·ªõn\n    - Ch·ªçn rau theo m√πa\n    - S·ª≠ d·ª•ng hoa qu·∫£ ƒë√¥ng l·∫°nh\n    - Mua th·ª±c ph·∫©m kh√¥ng h·ªèng v·ªõi s·ªë l∆∞·ª£ng l·ªõn\n\n    C√¢n Nh·∫Øc Dinh D∆∞·ª°ng:\n    - 100% kh√¥ng gluten\n    - Protein cao cho ph·ª•c h·ªìi c∆° b·∫Øp\n    - Carbohydrate ph·ª©c t·∫°p cho nƒÉng l∆∞·ª£ng b·ªÅn v·ªØng\n    - Ch·∫•t b√©o l√†nh m·∫°nh cho c√¢n b·∫±ng hormone\n\n    Khuy·∫øn Ngh·ªã Th·ª±c Ph·∫©m B·ªï Sung:\n    - Multivitamin\n    - Omega-3\n    - Vitamin D\n    - Magie\n\n    Ghi Ch√∫:\n    - ƒêi·ªÅu ch·ªânh kh·∫©u ph·∫ßn theo c∆∞·ªùng ƒë·ªô t·∫≠p luy·ªán h√†ng ng√†y\n    - Tham kh·∫£o √Ω ki·∫øn chuy√™n gia dinh d∆∞·ª°ng cho k·∫ø ho·∫°ch c√° nh√¢n h√≥a\n    - Theo d√µi th√†nh ph·∫ßn c∆° th·ªÉ v√† hi·ªáu su·∫•t\n    </ƒë·∫ßu_ra_l√Ω_t∆∞·ªüng>\n\n    Gi·∫£i ph√°p ƒë√°p ·ª©ng t·∫•t c·∫£ y√™u c·∫ßu b·∫Øt bu·ªôc v·ªõi k·∫ø ho·∫°ch b·ªØa ƒÉn ch√≠nh x√°c, t·∫≠p trung v√†o v·∫≠n ƒë·ªông vi√™n. N√≥ cung c·∫•p chi·∫øn l∆∞·ª£c dinh d∆∞·ª°ng h√†ng ng√†y ho√†n ch·ªânh v·ªõi l∆∞·ª£ng calo ch√≠nh x√°c, ph√¢n chia ch·∫•t dinh d∆∞·ª°ng ƒëa l∆∞·ª£ng, th·ªùi gian b·ªØa ƒÉn, v√† c√¢n nh·∫Øc kh√¥ng gluten. K·∫ø ho·∫°ch ƒë∆∞·ª£c thi·∫øt k·∫ø ri√™ng ƒë·ªÉ h·ªó tr·ª£ hi·ªáu su·∫•t CrossFit c∆∞·ªùng ƒë·ªô cao v·ªõi dinh d∆∞·ª°ng c√¢n b·∫±ng v√† th√†nh ph·∫ßn b·ªØa ƒÉn chi·∫øn l∆∞·ª£c.\n    \"\"\"\n\n    messages = []\n    add_user_message(messages, prompt)\n    return chat(messages)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pqr678",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluator.run_evaluation(\n",
    "    run_prompt_function=run_prompt, \n",
    "    dataset_file=\"dataset.vn.json\",\n",
    "    extra_criteria=\"\"\"\n",
    "    ƒê·∫ßu ra n√™n bao g·ªìm:\n",
    "    - T·ªïng l∆∞·ª£ng calo h√†ng ng√†y\n",
    "    - Ph√¢n chia ch·∫•t dinh d∆∞·ª°ng ƒëa l∆∞·ª£ng (macro)\n",
    "    - B·ªØa ƒÉn v·ªõi th·ª±c ph·∫©m ch√≠nh x√°c, kh·∫©u ph·∫ßn v√† th·ªùi gian\n",
    "    \"\"\",\n",
    "    json_output_file=\"output.vn.json\",\n",
    "    html_output_file=\"output.vn.html\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}