{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47ac10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import thư viện\n",
    "import json\n",
    "import concurrent.futures\n",
    "import re\n",
    "from textwrap import dedent\n",
    "from statistics import mean\n",
    "from dotenv import load_dotenv\n",
    "from anthropic import Anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b784b94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khởi tạo Client và các hàm hỗ trợ\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = Anthropic()\n",
    "model = \"claude-3-5-haiku-latest\"\n",
    "\n",
    "\n",
    "def add_user_message(messages, text):\n",
    "    user_message = {\"role\": \"user\", \"content\": text}\n",
    "    messages.append(user_message)\n",
    "\n",
    "\n",
    "def add_assistant_message(messages, text):\n",
    "    assistant_message = {\"role\": \"assistant\", \"content\": text}\n",
    "    messages.append(assistant_message)\n",
    "\n",
    "\n",
    "def chat(messages, system=None, temperature=1.0, stop_sequences=[]):\n",
    "    params = {\n",
    "        \"model\": model,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "        \"stop_sequences\": stop_sequences,\n",
    "    }\n",
    "\n",
    "    if system:\n",
    "        params[\"system\"] = system\n",
    "\n",
    "    message = client.messages.create(**params)\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Công cụ tạo báo cáo tiếng Việt\n",
    "def generate_prompt_evaluation_report(evaluation_results):\n",
    "    total_tests = len(evaluation_results)\n",
    "    scores = [result[\"score\"] for result in evaluation_results]\n",
    "    avg_score = mean(scores) if scores else 0\n",
    "    max_possible_score = 10\n",
    "    pass_rate = (\n",
    "        100 * len([s for s in scores if s >= 7]) / total_tests\n",
    "        if total_tests\n",
    "        else 0\n",
    "    )\n",
    "\n",
    "    html = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"vi\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "        <title>Báo Cáo Đánh Giá Prompt</title>\n",
    "        <style>\n",
    "            body {{\n",
    "                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "                line-height: 1.6;\n",
    "                margin: 0;\n",
    "                padding: 20px;\n",
    "                color: #333;\n",
    "            }}\n",
    "            .header {{\n",
    "                background-color: #f0f0f0;\n",
    "                padding: 20px;\n",
    "                border-radius: 5px;\n",
    "                margin-bottom: 20px;\n",
    "            }}\n",
    "            .summary-stats {{\n",
    "                display: flex;\n",
    "                justify-content: space-between;\n",
    "                flex-wrap: wrap;\n",
    "                gap: 10px;\n",
    "            }}\n",
    "            .stat-box {{\n",
    "                background-color: #fff;\n",
    "                border-radius: 5px;\n",
    "                padding: 15px;\n",
    "                box-shadow: 0 2px 5px rgba(0,0,0,0.1);\n",
    "                flex-basis: 30%;\n",
    "                min-width: 200px;\n",
    "            }}\n",
    "            .stat-value {{\n",
    "                font-size: 24px;\n",
    "                font-weight: bold;\n",
    "                margin-top: 5px;\n",
    "            }}\n",
    "            table {{\n",
    "                width: 100%;\n",
    "                border-collapse: collapse;\n",
    "                margin-top: 20px;\n",
    "            }}\n",
    "            th {{\n",
    "                background-color: #4a4a4a;\n",
    "                color: white;\n",
    "                text-align: left;\n",
    "                padding: 12px;\n",
    "            }}\n",
    "            td {{\n",
    "                padding: 10px;\n",
    "                border-bottom: 1px solid #ddd;\n",
    "                vertical-align: top;\n",
    "            }}\n",
    "            tr:nth-child(even) {{\n",
    "                background-color: #f9f9f9;\n",
    "            }}\n",
    "            .output-cell {{\n",
    "                white-space: pre-wrap;\n",
    "            }}\n",
    "            .score {{\n",
    "                font-weight: bold;\n",
    "                padding: 5px 10px;\n",
    "                border-radius: 3px;\n",
    "                display: inline-block;\n",
    "            }}\n",
    "            .score-high {{\n",
    "                background-color: #c8e6c9;\n",
    "                color: #2e7d32;\n",
    "            }}\n",
    "            .score-medium {{\n",
    "                background-color: #fff9c4;\n",
    "                color: #f57f17;\n",
    "            }}\n",
    "            .score-low {{\n",
    "                background-color: #ffcdd2;\n",
    "                color: #c62828;\n",
    "            }}\n",
    "            .output {{\n",
    "                overflow: auto;\n",
    "                white-space: pre-wrap;\n",
    "            }}\n",
    "            .output pre {{\n",
    "                background-color: #f5f5f5;\n",
    "                border: 1px solid #ddd;\n",
    "                border-radius: 4px;\n",
    "                padding: 10px;\n",
    "                margin: 0;\n",
    "                font-family: 'Consolas', 'Monaco', 'Courier New', monospace;\n",
    "                font-size: 14px;\n",
    "                line-height: 1.4;\n",
    "                color: #333;\n",
    "                box-shadow: inset 0 1px 3px rgba(0, 0, 0, 0.1);\n",
    "                overflow-x: auto;\n",
    "                white-space: pre-wrap;\n",
    "                word-wrap: break-word;\n",
    "            }}\n",
    "            td {{\n",
    "                width: 20%;\n",
    "            }}\n",
    "            .score-col {{\n",
    "                width: 80px;\n",
    "            }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div class=\"header\">\n",
    "            <h1>Báo Cáo Đánh Giá Prompt</h1>\n",
    "            <div class=\"summary-stats\">\n",
    "                <div class=\"stat-box\">\n",
    "                    <div>Tổng Số Test Case</div>\n",
    "                    <div class=\"stat-value\">{total_tests}</div>\n",
    "                </div>\n",
    "                <div class=\"stat-box\">\n",
    "                    <div>Điểm Trung Bình</div>\n",
    "                    <div class=\"stat-value\">{avg_score:.1f} / {max_possible_score}</div>\n",
    "                </div>\n",
    "                <div class=\"stat-box\">\n",
    "                    <div>Tỷ Lệ Đạt (≥7)</div>\n",
    "                    <div class=\"stat-value\">{pass_rate:.1f}%</div>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "        <table>\n",
    "            <thead>\n",
    "                <tr>\n",
    "                    <th>Kịch Bản</th>\n",
    "                    <th>Đầu Vào Prompt</th>\n",
    "                    <th>Tiêu Chí Giải Pháp</th>\n",
    "                    <th>Kết Quả</th>\n",
    "                    <th>Điểm</th>\n",
    "                    <th>Lý Luận</th>\n",
    "                </tr>\n",
    "            </thead>\n",
    "            <tbody>\n",
    "    \"\"\"\n",
    "\n",
    "    for result in evaluation_results:\n",
    "        prompt_inputs_html = \"<br>\".join(\n",
    "            [\n",
    "                f\"<strong>{key}:</strong> {value}\"\n",
    "                for key, value in result[\"test_case\"][\"prompt_inputs\"].items()\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        criteria_string = \"<br>• \".join(\n",
    "            result[\"test_case\"][\"solution_criteria\"]\n",
    "        )\n",
    "\n",
    "        score = result[\"score\"]\n",
    "        if score >= 8:\n",
    "            score_class = \"score-high\"\n",
    "        elif score <= 5:\n",
    "            score_class = \"score-low\"\n",
    "        else:\n",
    "            score_class = \"score-medium\"\n",
    "\n",
    "        html += f\"\"\"\n",
    "            <tr>\n",
    "                <td>{result[\"test_case\"][\"scenario\"]}</td>\n",
    "                <td class=\"prompt-inputs\">{prompt_inputs_html}</td>\n",
    "                <td class=\"criteria\">• {criteria_string}</td>\n",
    "                <td class=\"output\"><pre>{result[\"output\"]}</pre></td>\n",
    "                <td class=\"score-col\"><span class=\"score {score_class}\">{score}</span></td>\n",
    "                <td class=\"reasoning\">{result[\"reasoning\"]}</td>\n",
    "            </tr>\n",
    "        \"\"\"\n",
    "\n",
    "    html += \"\"\"\n",
    "            </tbody>\n",
    "        </table>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triển khai PromptEvaluator với prompt tiếng Việt\n",
    "class PromptEvaluator:\n",
    "    def __init__(self, max_concurrent_tasks=3):\n",
    "        self.max_concurrent_tasks = max_concurrent_tasks\n",
    "\n",
    "    def render(self, template_string, variables):\n",
    "        placeholders = re.findall(r\"{([^{}]+)}\", template_string)\n",
    "        result = template_string\n",
    "        for placeholder in placeholders:\n",
    "            if placeholder in variables:\n",
    "                result = result.replace(\n",
    "                    \"{\" + placeholder + \"}\", str(variables[placeholder])\n",
    "                )\n",
    "        return result.replace(\"{{\", \"{\").replace(\"}}\", \"}\")\n",
    "\n",
    "    def generate_unique_ideas(self, task_description, prompt_inputs_spec, num_cases):\n",
    "        \"\"\"Tạo danh sách ý tưởng độc đáo cho test case dựa trên mô tả tác vụ\"\"\"\n",
    "        prompt = \"\"\"\n",
    "        Tạo {num_cases} ý tưởng độc đáo và đa dạng để test một prompt thực hiện tác vụ sau:\n",
    "        \n",
    "        <mô_tả_tác_vụ>\n",
    "        {task_description}\n",
    "        </mô_tả_tác_vụ>\n",
    "\n",
    "        Prompt sẽ nhận các đầu vào sau:\n",
    "        <đầu_vào_prompt>\n",
    "        {prompt_inputs_spec}\n",
    "        </đầu_vào_prompt>\n",
    "        \n",
    "        Mỗi ý tưởng nên đại diện cho một kịch bản hoặc ví dụ riêng biệt để test các khía cạnh khác nhau của tác vụ.\n",
    "        \n",
    "        Định dạng đầu ra:\n",
    "        Cung cấp phản hồi dưới dạng mảng JSON có cấu trúc, trong đó mỗi item là mô tả ngắn gọn về ý tưởng.\n",
    "        \n",
    "        Đảm bảo mỗi ý tưởng:\n",
    "        - Rõ ràng khác biệt với các ý tưởng khác\n",
    "        - Liên quan đến mô tả tác vụ\n",
    "        - Đủ cụ thể để hướng dẫn tạo test case đầy đủ\n",
    "        - Nhanh chóng giải quyết mà không cần tính toán phức tạp hoặc xử lý nhiều bước\n",
    "        - Có thể giải quyết với không quá 400 token đầu ra\n",
    "\n",
    "        Nhớ rằng, chỉ tạo {num_cases} ý tưởng độc đáo\n",
    "        \"\"\"\n",
    "\n",
    "        system_prompt = \"Bạn là một nhà thiết kế kịch bản test chuyên tạo các kịch bản test đa dạng và độc đáo.\"\n",
    "\n",
    "        example_prompt_inputs = \"\"\n",
    "        for key, value in prompt_inputs_spec.items():\n",
    "            val = value.replace(\"\\n\", \"\\\\n\")\n",
    "            example_prompt_inputs += f'\"{key}\": str # {val},'\n",
    "\n",
    "        rendered_prompt = self.render(\n",
    "            dedent(prompt),\n",
    "            {\n",
    "                \"task_description\": task_description,\n",
    "                \"num_cases\": num_cases,\n",
    "                \"prompt_inputs_spec\": example_prompt_inputs,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        messages = []\n",
    "        add_user_message(messages, rendered_prompt)\n",
    "        add_assistant_message(messages, \"```json\")\n",
    "        text = chat(\n",
    "            messages,\n",
    "            stop_sequences=[\"```\"],\n",
    "            system=system_prompt,\n",
    "            temperature=1.0,\n",
    "        )\n",
    "\n",
    "        return json.loads(text)\n",
    "\n",
    "    def generate_test_case(self, task_description, idea, prompt_inputs_spec={}):\n",
    "        \"\"\"Tạo một test case dựa trên mô tả tác vụ và ý tưởng cụ thể\"\"\"\n",
    "\n",
    "        example_prompt_inputs = \"\"\n",
    "        for key, value in prompt_inputs_spec.items():\n",
    "            val = value.replace(\"\\n\", \"\\\\n\")\n",
    "            example_prompt_inputs += f'\"{key}\": \"GIÁ_TRỊ_VÍ_DỤ\", // {val}\\n'\n",
    "\n",
    "        allowed_keys = \", \".join(\n",
    "            [f'\"{key}\"' for key in prompt_inputs_spec.keys()]\n",
    "        )\n",
    "\n",
    "        prompt = \"\"\"\n",
    "        Tạo một test case chi tiết cho đánh giá prompt dựa trên:\n",
    "        \n",
    "        <mô_tả_tác_vụ>\n",
    "        {task_description}\n",
    "        </mô_tả_tác_vụ>\n",
    "        \n",
    "        <ý_tưởng_cụ_thể>\n",
    "        {idea}\n",
    "        </ý_tưởng_cụ_thể>\n",
    "        \n",
    "        <khóa_đầu_vào_được_phép>\n",
    "        {allowed_keys}\n",
    "        </khóa_đầu_vào_được_phép>\n",
    "        \n",
    "        Định dạng đầu ra:\n",
    "        ```json\n",
    "        {{\n",
    "            \"prompt_inputs\": {{\n",
    "            {example_prompt_inputs}\n",
    "            }},\n",
    "            \"solution_criteria\": [\"tiêu chí 1\", \"tiêu chí 2\", ...]\n",
    "        }}\n",
    "        ```\n",
    "        \n",
    "        YÊU CẦU QUAN TRỌNG:\n",
    "        - Bạn CHỈ ĐƯỢC sử dụng các khóa đầu vào chính xác sau trong prompt_inputs: {allowed_keys}        \n",
    "        - KHÔNG thêm bất kỳ khóa bổ sung nào vào prompt_inputs\n",
    "        - Tất cả khóa được liệt kê trong khóa_đầu_vào_được_phép phải được bao gồm trong phản hồi\n",
    "        - Làm cho test case thực tế và hữu ích về mặt thực tiễn\n",
    "        - Bao gồm các tiêu chí giải pháp có thể đo lường và súc tích\n",
    "        - Test case nên được điều chỉnh theo ý tưởng cụ thể được cung cấp\n",
    "        - Nhanh chóng giải quyết mà không cần tính toán phức tạp hoặc xử lý nhiều bước\n",
    "        - Có thể giải quyết với không quá 400 token đầu ra\n",
    "        \"\"\"\n",
    "\n",
    "        system_prompt = \"Bạn là một người tạo test case chuyên thiết kế các kịch bản đánh giá.\"\n",
    "\n",
    "        rendered_prompt = self.render(\n",
    "            dedent(prompt),\n",
    "            {\n",
    "                \"allowed_keys\": allowed_keys,\n",
    "                \"task_description\": task_description,\n",
    "                \"idea\": idea,\n",
    "                \"example_prompt_inputs\": example_prompt_inputs,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        messages = []\n",
    "        add_user_message(messages, rendered_prompt)\n",
    "        add_assistant_message(messages, \"```json\")\n",
    "        text = chat(\n",
    "            messages,\n",
    "            stop_sequences=[\"```\"],\n",
    "            system=system_prompt,\n",
    "            temperature=0.7,\n",
    "        )\n",
    "\n",
    "        test_case = json.loads(text)\n",
    "        test_case[\"task_description\"] = task_description\n",
    "        test_case[\"scenario\"] = idea\n",
    "\n",
    "        return test_case\n",
    "\n",
    "    def generate_dataset(self, task_description, prompt_inputs_spec={}, num_cases=1, output_file=\"dataset.json\"):\n",
    "        \"\"\"Tạo test dataset dựa trên mô tả tác vụ và lưu vào file\"\"\"\n",
    "        ideas = self.generate_unique_ideas(\n",
    "            task_description, prompt_inputs_spec, num_cases\n",
    "        )\n",
    "\n",
    "        dataset = []\n",
    "        completed = 0\n",
    "        total = len(ideas)\n",
    "        last_reported_percentage = 0\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor(\n",
    "            max_workers=self.max_concurrent_tasks\n",
    "        ) as executor:\n",
    "            future_to_idea = {\n",
    "                executor.submit(\n",
    "                    self.generate_test_case,\n",
    "                    task_description,\n",
    "                    idea,\n",
    "                    prompt_inputs_spec,\n",
    "                ): idea\n",
    "                for idea in ideas\n",
    "            }\n",
    "\n",
    "            for future in concurrent.futures.as_completed(future_to_idea):\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    completed += 1\n",
    "                    current_percentage = int((completed / total) * 100)\n",
    "                    milestone_percentage = (current_percentage // 20) * 20\n",
    "\n",
    "                    if milestone_percentage > last_reported_percentage:\n",
    "                        print(f\"Đã tạo {completed}/{total} test case\")\n",
    "                        last_reported_percentage = milestone_percentage\n",
    "\n",
    "                    dataset.append(result)\n",
    "                except Exception as e:\n",
    "                    print(f\"Lỗi khi tạo test case: {e}\")\n",
    "\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(dataset, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    def grade_output(self, test_case, output, extra_criteria):\n",
    "        \"\"\"Chấm điểm đầu ra của test case sử dụng model\"\"\"\n",
    "\n",
    "        prompt_inputs = \"\"\n",
    "        for key, value in test_case[\"prompt_inputs\"].items():\n",
    "            val = value.replace(\"\\n\", \"\\\\n\")\n",
    "            prompt_inputs += f'\"{key}\":\"{val}\",\\n'\n",
    "\n",
    "        extra_criteria_section = \"\"\n",
    "        if extra_criteria:\n",
    "            extra_criteria_template = \"\"\"\n",
    "            Yêu cầu bắt buộc - BẤT KỲ VI PHẠM NÀO CŨNG DẪN ĐẾN THẤT BẠI TỰ ĐỘNG (điểm 3 hoặc thấp hơn):\n",
    "            <tiêu_chí_quan_trọng_bổ_sung>\n",
    "            {extra_criteria}\n",
    "            </tiêu_chí_quan_trọng_bổ_sung>\n",
    "            \"\"\"\n",
    "            extra_criteria_section = self.render(\n",
    "                dedent(extra_criteria_template),\n",
    "                {\"extra_criteria\": extra_criteria},\n",
    "            )\n",
    "\n",
    "        eval_template = \"\"\"\n",
    "        Nhiệm vụ của bạn là đánh giá giải pháp do AI tạo ra sau đây với ĐỘ NGHIÊM NGẶT CỰC CAO.\n",
    "\n",
    "        Mô tả tác vụ gốc:\n",
    "        <mô_tả_tác_vụ>\n",
    "        {task_description}\n",
    "        </mô_tả_tác_vụ>\n",
    "\n",
    "        Đầu vào tác vụ gốc:\n",
    "        <đầu_vào_tác_vụ>\n",
    "        {{ {prompt_inputs} }}\n",
    "        </đầu_vào_tác_vụ>\n",
    "\n",
    "        Giải pháp cần đánh giá:\n",
    "        <giải_pháp>\n",
    "        {output}\n",
    "        </giải_pháp>\n",
    "\n",
    "        Tiêu chí bạn nên sử dụng để đánh giá giải pháp:\n",
    "        <tiêu_chí>\n",
    "        {solution_criteria}\n",
    "        </tiêu_chí>\n",
    "\n",
    "        {extra_criteria_section}\n",
    "\n",
    "        Hướng dẫn chấm điểm:\n",
    "        * Điểm 1-3: Giải pháp không đáp ứng một hoặc nhiều yêu cầu BẮT BUỘC\n",
    "        * Điểm 4-6: Giải pháp đáp ứng tất cả yêu cầu bắt buộc nhưng có thiếu sót đáng kể trong tiêu chí phụ\n",
    "        * Điểm 7-8: Giải pháp đáp ứng tất cả yêu cầu bắt buộc và hầu hết tiêu chí phụ, với các vấn đề nhỏ\n",
    "        * Điểm 9-10: Giải pháp đáp ứng tất cả tiêu chí bắt buộc và phụ\n",
    "\n",
    "        Định dạng đầu ra\n",
    "        Cung cấp đánh giá của bạn dưới dạng đối tượng JSON có cấu trúc với các trường sau:\n",
    "        - \"strengths\": Mảng 1-3 điểm mạnh chính\n",
    "        - \"weaknesses\": Mảng 1-3 lĩnh vực chính cần cải thiện\n",
    "        - \"reasoning\": Giải thích súc tích về đánh giá tổng thể của bạn\n",
    "        - \"score\": Số từ 1-10\n",
    "\n",
    "        Phản hồi bằng JSON. Giữ phản hồi súc tích và trực tiếp.\n",
    "        \"\"\"\n",
    "\n",
    "        eval_prompt = self.render(\n",
    "            dedent(eval_template),\n",
    "            {\n",
    "                \"task_description\": test_case[\"task_description\"],\n",
    "                \"prompt_inputs\": prompt_inputs,\n",
    "                \"output\": output,\n",
    "                \"solution_criteria\": \"\\n\".join(test_case[\"solution_criteria\"]),\n",
    "                \"extra_criteria_section\": extra_criteria_section,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        messages = []\n",
    "        add_user_message(messages, eval_prompt)\n",
    "        add_assistant_message(messages, \"```json\")\n",
    "        eval_text = chat(\n",
    "            messages,\n",
    "            stop_sequences=[\"```\"],\n",
    "            temperature=0.0,\n",
    "        )\n",
    "        return json.loads(eval_text)\n",
    "\n",
    "    def run_test_case(self, test_case, run_prompt_function, extra_criteria=None):\n",
    "        \"\"\"Chạy test case và chấm điểm kết quả\"\"\"\n",
    "        output = run_prompt_function(test_case[\"prompt_inputs\"])\n",
    "\n",
    "        model_grade = self.grade_output(test_case, output, extra_criteria)\n",
    "        model_score = model_grade[\"score\"]\n",
    "        reasoning = model_grade[\"reasoning\"]\n",
    "\n",
    "        return {\n",
    "            \"output\": output,\n",
    "            \"test_case\": test_case,\n",
    "            \"score\": model_score,\n",
    "            \"reasoning\": reasoning,\n",
    "        }\n",
    "\n",
    "    def run_evaluation(self, run_prompt_function, dataset_file, extra_criteria=None, json_output_file=\"output.json\", html_output_file=\"output.html\"):\n",
    "        \"\"\"Chạy đánh giá trên tất cả test case trong dataset\"\"\"\n",
    "        with open(dataset_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            dataset = json.load(f)\n",
    "\n",
    "        results = []\n",
    "        completed = 0\n",
    "        total = len(dataset)\n",
    "        last_reported_percentage = 0\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor(\n",
    "            max_workers=self.max_concurrent_tasks\n",
    "        ) as executor:\n",
    "            future_to_test_case = {\n",
    "                executor.submit(\n",
    "                    self.run_test_case,\n",
    "                    test_case,\n",
    "                    run_prompt_function,\n",
    "                    extra_criteria,\n",
    "                ): test_case\n",
    "                for test_case in dataset\n",
    "            }\n",
    "\n",
    "            for future in concurrent.futures.as_completed(future_to_test_case):\n",
    "                result = future.result()\n",
    "                completed += 1\n",
    "                current_percentage = int((completed / total) * 100)\n",
    "                milestone_percentage = (current_percentage // 20) * 20\n",
    "\n",
    "                if milestone_percentage > last_reported_percentage:\n",
    "                    print(f\"Đã chấm điểm {completed}/{total} test case\")\n",
    "                    last_reported_percentage = milestone_percentage\n",
    "                results.append(result)\n",
    "\n",
    "        average_score = mean([result[\"score\"] for result in results])\n",
    "        print(f\"Điểm trung bình: {average_score}\")\n",
    "\n",
    "        with open(json_output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        html = generate_prompt_evaluation_report(results)\n",
    "        with open(html_output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(html)\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ghi789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo một instance của PromptEvaluator\n",
    "# Tăng max_concurrent_tasks để có tính đồng thời cao hơn, nhưng cẩn thận với lỗi rate limit!\n",
    "evaluator = PromptEvaluator(max_concurrent_tasks=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jkl012",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = evaluator.generate_dataset(\n",
    "    # Mô tả mục đích hoặc mục tiêu của prompt bạn đang cố gắng test\n",
    "    task_description=\"Viết kế hoạch bữa ăn 1 ngày gọn gàng, súc tích cho một vận động viên\",\n",
    "    # Mô tả các đầu vào khác nhau mà prompt của bạn yêu cầu\n",
    "    prompt_inputs_spec={\n",
    "        \"height\": \"Chiều cao của vận động viên tính bằng cm\",\n",
    "        \"weight\": \"Cân nặng của vận động viên tính bằng kg\",\n",
    "        \"goal\": \"Mục tiêu của vận động viên\",\n",
    "        \"restriction\": \"Hạn chế chế độ ăn của vận động viên\"\n",
    "    },\n",
    "    # Nơi ghi dataset được tạo\n",
    "    output_file=\"dataset.vn.json\",\n",
    "    # Số lượng test case cần tạo (khuyến nghị giữ số này thấp nếu bạn gặp lỗi rate limit)\n",
    "    num_cases=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mno345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Định nghĩa và chạy prompt bạn muốn đánh giá, trả về đầu ra model thô\n",
    "# Hàm này được thực thi một lần cho mỗi test case\n",
    "def run_prompt(prompt_inputs):\n",
    "    prompt = f\"\"\"\n",
    "    Người này nên ăn gì:\n",
    "\n",
    "    - Chiều cao: {prompt_inputs[\"height\"]} cm\n",
    "    - Cân nặng: {prompt_inputs[\"weight\"]} kg\n",
    "    - Mục tiêu: {prompt_inputs[\"goal\"]}\n",
    "    - Hạn chế chế độ ăn: {prompt_inputs[\"restriction\"]}\n",
    "    \n",
    "    Hãy tạo kế hoạch bữa ăn 1 ngày chi tiết và thực tế.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = []\n",
    "    add_user_message(messages, prompt)\n",
    "    return chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pqr678",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluator.run_evaluation(\n",
    "    run_prompt_function=run_prompt, \n",
    "    dataset_file=\"dataset.vn.json\",\n",
    "    extra_criteria=\"\"\"\n",
    "    Đầu ra nên bao gồm:\n",
    "    - Tổng lượng calo hàng ngày\n",
    "    - Phân chia chất dinh dưỡng đa lượng (macro)\n",
    "    - Bữa ăn với thực phẩm chính xác, khẩu phần và thời gian\n",
    "    \"\"\",\n",
    "    json_output_file=\"output.vn.json\",\n",
    "    html_output_file=\"output.vn.html\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}